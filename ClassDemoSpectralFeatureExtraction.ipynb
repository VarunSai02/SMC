{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2fff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Feature Extraction\n",
    "# Additional Documentation: https://librosa.org/doc/main/feature.html#spectral-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335fc10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "from parselmouth.praat import call\n",
    "import parselmouth\n",
    "import statistics\n",
    "import random\n",
    "import soundfile as sf \n",
    "from parselmouth.praat import call\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from librosa import feature\n",
    "import csv\n",
    "from tempfile import mktemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44affc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_files(folder_path):\n",
    "    audio_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".wav\"):  # Assuming your audio files have .wav extension\n",
    "            audio_files.append(os.path.join(folder_path, filename))\n",
    "    return audio_files\n",
    "\n",
    "# Paths to your concussion and no concussion folders\n",
    "concussion_folder = \"C:\\\\USF\\\\Semester2\\\\SmartAndConnectedHealth\\\\FinalProject\\\\Concussion\"\n",
    "no_concussion_folder = \"C:\\\\USF\\\\Semester2\\\\SmartAndConnectedHealth\\\\FinalProject\\\\NoConcussion\"\n",
    "\n",
    "# Extract audio files from both folders\n",
    "concussion_files = extract_audio_files(concussion_folder)\n",
    "no_concussion_files = extract_audio_files(no_concussion_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563cab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from audio\n",
    "def get_feature_vector(audio_file):\n",
    "    y, sr = librosa.load(audio_file, sr=None)  # Load audio file\n",
    "    \n",
    "    # Extract features\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n",
    "    lpc = np.std(librosa.lpc(y, order=16))  # Specify the order parameter\n",
    "    \n",
    "    # Additional features\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "    tempo = librosa.beat.tempo(y=y, sr=sr)[0]\n",
    "    \n",
    "    # Combine features into a single feature vector\n",
    "    feature_vector = [spectral_centroid, spectral_bandwidth, spectral_rolloff,\n",
    "                      zero_crossing_rate, *mfccs, lpc, spectral_contrast,\n",
    "                      chroma_stft, tempo]\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3764dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder function for feature extraction\n",
    "def extract_features(audio_files):\n",
    "    features = []\n",
    "    for file in audio_files:\n",
    "        feature_vector = get_feature_vector(file)\n",
    "        features.append(feature_vector)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90aec035-b171-4f6f-b6cf-835ed6749d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation: Add noise, pitch shifting, and tempo shifting\n",
    "def augment_data(audio_files):\n",
    "    augmented_files = []\n",
    "    for file in audio_files:\n",
    "        y, sr = librosa.load(file, sr=None)  # Load audio file\n",
    "        # Add noise\n",
    "        y_noise = y + 0.005 * np.random.randn(len(y))\n",
    "        noise_file = mktemp(suffix='.wav')  # Using mktemp to create temporary file names\n",
    "        sf.write(noise_file, y_noise, sr)  # Writing the audio file using soundfile\n",
    "        augmented_files.append(noise_file)\n",
    "        # Pitch shifting\n",
    "        n_steps = random.randint(-3, 3)\n",
    "        y_pitch_shift = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
    "        pitch_shift_file = mktemp(suffix='.wav')  # Using mktemp to create temporary file names\n",
    "        sf.write(pitch_shift_file, y_pitch_shift, sr)  # Writing the audio file using soundfile\n",
    "        augmented_files.append(pitch_shift_file)\n",
    "        # Tempo shifting\n",
    "        y_tempo_shift = librosa.effects.time_stretch(y, rate=1.2)\n",
    "        tempo_shift_file = mktemp(suffix='.wav')  # Using mktemp to create temporary file names\n",
    "        sf.write(tempo_shift_file, y_tempo_shift, sr)  # Writing the audio file using soundfile\n",
    "        augmented_files.append(tempo_shift_file)\n",
    "    return augmented_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df71491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for concussion files\n",
    "concussion_features = extract_features(concussion_files)\n",
    "# Augment data for concussion files\n",
    "augmented_concussion_files = augment_data(concussion_files)\n",
    "augmented_concussion_features = extract_features(augmented_concussion_files)\n",
    "\n",
    "# Extract features for no concussion files\n",
    "no_concussion_features = extract_features(no_concussion_files)\n",
    "# Augment data for no concussion files\n",
    "augmented_no_concussion_files = augment_data(no_concussion_files)\n",
    "augmented_no_concussion_features = extract_features(augmented_no_concussion_files)\n",
    "\n",
    "# Combine features and labels\n",
    "all_features = concussion_features + augmented_concussion_features + no_concussion_features + augmented_no_concussion_features\n",
    "all_labels = [1] * (len(concussion_features) + len(augmented_concussion_features)) + [0] * (len(no_concussion_features) + len(augmented_no_concussion_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1755a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write features and labels to CSV\n",
    "header = ['SpectralCentroid', 'SpectralBandwidth', 'SpectralRolloff',\n",
    "          'ZeroCrossingRate', 'MFCC1', 'MFCC2', 'MFCC3', 'MFCC4', 'MFCC5',\n",
    "          'MFCC6', 'MFCC7', 'MFCC8', 'MFCC9', 'MFCC10', 'MFCC11', 'MFCC12',\n",
    "          'MFCC13', 'LPC', 'SpectralContrast', 'ChromaSTFT', 'Tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7cdda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('concussion_classification_features.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(all_features)\n",
    "\n",
    "with open('concussion_classification_labels.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Label'])\n",
    "    writer.writerows([[label] for label in all_labels])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
